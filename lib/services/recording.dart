
import 'dart:convert';
import 'dart:io';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'dart:async'; // ç¢ºä¿å°å…¥ dart:async


class AudioRecorder {
  FlutterSoundRecorder? _recorder;
  bool _isRecording = false;
  String? _recordedFilePath;


  /// åˆå§‹åŒ–éŒ„éŸ³å™¨ï¼Œä¸¦è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
  Future<void> initRecorder() async {
    try {
      _recorder = FlutterSoundRecorder();
      await _recorder!.openRecorder();
      var status = await Permission.microphone.request();
      if (!status.isGranted) {
        print("âŒ éº¥å…‹é¢¨æ¬Šé™æœªæˆæ¬Š");
      }
    } catch (e) {
      print("âŒ initRecorder ç™¼ç”ŸéŒ¯èª¤: $e");
    }
  }

  /// é–‹å§‹éŒ„éŸ³ï¼Œå°‡éŸ³æª”å„²å­˜è‡³è‡¨æ™‚ç›®éŒ„
  Future<void> startRecording() async {
    if (_isRecording) return;
    try {
      final dir = await getTemporaryDirectory();
      String path = '${dir.path}/voice_record.aac';
      await _recorder!.startRecorder(toFile: path, codec: Codec.aacADTS);
      _isRecording = true;
      _recordedFilePath = path;
      print("ğŸ¤ éŒ„éŸ³é–‹å§‹... å„²å­˜åˆ°: $path");
    } catch (e) {
      print("âŒ startRecording ç™¼ç”ŸéŒ¯èª¤: $e");
    }
  }

  /// åœæ­¢éŒ„éŸ³ä¸¦é€²è¡Œåˆ†æï¼ˆè½‰è­¯èˆ‡è©•åˆ†ï¼‰
  Future<void> stopRecordingAndEvaluate() async {
    if (!_isRecording) return;
    try {
      await _recorder!.stopRecorder();
      _isRecording = false;
      print("âœ… éŒ„éŸ³å®Œæˆï¼Œæª”æ¡ˆå„²å­˜è·¯å¾‘: $_recordedFilePath");

      if (_recordedFilePath != null) {
        final text = await _transcribeAudioToText(_recordedFilePath!);
        if (text != null) {
          print("ğŸ“ Whisper è­¯æ–‡: $text");
          final evaluation = await _evaluateEnglish(text);
          if (evaluation != null) {
            print("ğŸ“Š GPT è©•åˆ†çµæœ:\n$evaluation");
          } else {
            print("âŒ GPT è©•åˆ†çµæœå–å¾—å¤±æ•—");
          }
        } else {
          print("âŒ Whisper è½‰è­¯çµæœç‚ºç©ºæˆ–è½‰è­¯å¤±æ•—");
        }
      }
    } catch (e) {
      print("âŒ stopRecordingAndEvaluate ç™¼ç”ŸéŒ¯èª¤: $e");
    }
  }

  /// å‘¼å« OpenAI Whisper API é€²è¡ŒèªéŸ³è½‰æ–‡å­— (åŠ å…¥é‡è©¦æ©Ÿåˆ¶)
  Future<String?> _transcribeAudioToText(String filePath) async {
    final apiKey = dotenv.env['GPT_KEY'];
    if (apiKey == null) {
      print("âŒ API é‡‘é‘°ä¸å­˜åœ¨ï¼Œè«‹ç¢ºèª .env ä¸­æœ‰ GPT_KEY");
      return null;
    }

    int retries = 0;
    const maxRetries = 3; // æœ€å¤šé‡è©¦ 3 æ¬¡
    const initialDelay = Duration(seconds: 1); // åˆå§‹å»¶é² 1 ç§’

    while (retries < maxRetries) {
      try {
        var request = http.MultipartRequest(
          'POST',
          Uri.parse('https://api.openai.com/v1/audio/transcriptions'),
        );
        request.headers['Authorization'] = 'Bearer $apiKey';
        request.files.add(
          await http.MultipartFile.fromPath(
            'file', // æ¬„ä½åç¨±æ‡‰ç‚º 'file'
            filePath,
            contentType: MediaType('audio', 'aac'),
          ),
        );
        request.fields['model'] = 'whisper-1';

        print("ğŸš€ æ­£åœ¨å˜—è©¦è½‰è­¯éŸ³æª” (ç¬¬ ${retries + 1} æ¬¡)...");
        var response = await request.send();

        if (response.statusCode == 200) {
          final resBody = await response.stream.bytesToString();
          print("âœ… Whisper è½‰è­¯æˆåŠŸ");
          return jsonDecode(resBody)['text'];
        } else if (response.statusCode == 429) {
          retries++;
          if (retries >= maxRetries) {
            print("âŒ Whisper è½‰è­¯å¤±æ•—: ${response.statusCode} (å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸)");
            final errorBody = await response.stream.bytesToString(); // å˜—è©¦è®€å–éŒ¯èª¤å…§å®¹
            print("éŒ¯èª¤å…§å®¹: $errorBody");
            return null;
          }
          // æŒ‡æ•¸é€€é¿ï¼šç­‰å¾…æ™‚é–“ = åˆå§‹å»¶é² * 2^(é‡è©¦æ¬¡æ•¸-1)
          final delay = initialDelay * (1 << (retries - 1));
          print(
            "â³ Whisper API é€Ÿç‡é™åˆ¶ (429)ï¼Œå°‡åœ¨ ${delay.inSeconds} ç§’å¾Œé‡è©¦ ($retries/$maxRetries)...",
          );
          await Future.delayed(delay); // ç­‰å¾…å¾Œé‡è©¦
        } else {
          // å…¶ä»– HTTP éŒ¯èª¤
          final errorBody = await response.stream.bytesToString();
          print("âŒ Whisper è½‰è­¯å¤±æ•—: ${response.statusCode}, éŒ¯èª¤å…§å®¹: $errorBody");
          return null; // ä¸é‡è©¦å…¶ä»–éŒ¯èª¤ï¼Œç›´æ¥è¿”å› null
        }
      } catch (e) {
        // ç¶²è·¯æˆ–å…¶ä»–ä¾‹å¤–éŒ¯èª¤
        print("âŒ _transcribeAudioToText ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤: $e");
        // ä¹Ÿå¯ä»¥è€ƒæ…®åœ¨æ­¤è™•åŠ å…¥é‡è©¦é‚è¼¯ï¼Œä½†é€šå¸¸é‡å°ç‰¹å®š HTTP éŒ¯èª¤é‡è©¦æ›´æœ‰æ•ˆ
        return null;
      }
    }
    // å¦‚æœè¿´åœˆçµæŸä»æœªæˆåŠŸ (ç†è«–ä¸Šæ‡‰è©²åœ¨è¿´åœˆå…§è¿”å›)
    print("âŒ Whisper è½‰è­¯åœ¨é‡è©¦å¾Œä»ç„¶å¤±æ•—");
    return null;
  }

  /// å‘¼å« OpenAI GPT API æ ¹æ“šè½‰è­¯çµæœçµ¦å‡ºè©•åˆ† (åŒæ¨£å¯ä»¥è€ƒæ…®åŠ å…¥é‡è©¦)
  Future<String?> _evaluateEnglish(String text) async {
    final apiKey = dotenv.env['GPT_KEY'];
    if (apiKey == null) {
      print("âŒ API é‡‘é‘°ä¸å­˜åœ¨");
      return null;
    }

    // --- GPT API ä¹Ÿå¯ä»¥åŠ å…¥é¡ä¼¼çš„é‡è©¦é‚è¼¯ ---
    int retries = 0;
    const maxRetries = 3;
    const initialDelay = Duration(seconds: 1);

    while (retries < maxRetries) {
      try {
        final response = await http.post(
          Uri.parse('https://api.openai.com/v1/chat/completions'),
          headers: {
            'Authorization': 'Bearer $apiKey',
            'Content-Type': 'application/json',
          },
          body: jsonEncode({
            "model": "gpt-3.5-turbo",
            "messages": [
              {
                "role": "system",
                "content":
                    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­è‹±æ–‡å£èªªæ•™å¸«ï¼Œè«‹æ ¹æ“šå­¸ç”Ÿèªªçš„å…§å®¹æä¾›è‹±æ–‡ç™¼éŸ³èˆ‡èªæ³•è©•åˆ†ï¼ˆæ»¿åˆ†10åˆ†ï¼‰ï¼Œè«‹åˆ—å‡ºå„ªé»èˆ‡ç¼ºé»ä¸¦çµ¦ä¸€æ®µå»ºè­°ã€‚",
              },
              {"role": "user", "content": text},
            ],
          }),
        );

        if (response.statusCode == 200) {
          final result = jsonDecode(response.body);
          print("âœ… GPT è©•åˆ†æˆåŠŸ");
          return result['choices'][0]['message']['content'];
        } else if (response.statusCode == 429) {
          retries++;
          if (retries >= maxRetries) {
            print("âŒ GPT è©•åˆ†å¤±æ•—: ${response.statusCode} (å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸)");
            print("éŒ¯èª¤å…§å®¹: ${response.body}");
            return null;
          }
          final delay = initialDelay * (1 << (retries - 1));
          print(
            "â³ GPT API é€Ÿç‡é™åˆ¶ (429)ï¼Œå°‡åœ¨ ${delay.inSeconds} ç§’å¾Œé‡è©¦ ($retries/$maxRetries)...",
          );
          await Future.delayed(delay);
        } else {
          print("âŒ GPT è©•åˆ†å¤±æ•—: ${response.statusCode}, éŒ¯èª¤å…§å®¹: ${response.body}");
          return null; // å…¶ä»–éŒ¯èª¤ç›´æ¥è¿”å›
        }
      } catch (e) {
        print("âŒ _evaluateEnglish ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤: $e");
        return null;
      }
    }
    print("âŒ GPT è©•åˆ†åœ¨é‡è©¦å¾Œä»ç„¶å¤±æ•—");
    return null;
  }

  // å–å¾—éŒ„éŸ³æª”æ¡ˆè·¯å¾‘
  String? getRecordedFilePath() {
    return _recordedFilePath;
  }


  // åˆ¤æ–·æ˜¯å¦æ­£åœ¨éŒ„éŸ³
  bool get isRecording => _isRecording;

  // é‡‹æ”¾éŒ„éŸ³å™¨è³‡æº
  void dispose() {
    _recorder?.closeRecorder();
  }

}
