import 'dart:convert';
import 'dart:io';
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';

import 'package:flutter_dotenv/flutter_dotenv.dart';

class WhisperService {
  final String apiKey = dotenv.env['API_KEY'] ?? '';
  final String modelUrl =
      'https://api-inference.huggingface.co/models/openai/whisper-large-v3';


  // å‚³é€éŒ„éŸ³æª”ä¸¦å°‡å›å‚³çš„æ–‡å­—å¯«å…¥ txt æª”
  Future<File?> transcribeAudioAndSave(File audioFile) async {
    try {
      final bytes = await audioFile.readAsBytes();
      final response = await http.post(
        Uri.parse(modelUrl),
        headers: {
          'Authorization': 'Bearer $apiKey',
          'Content-Type': 'audio/aac', // æ ¹æ“šä½ å¯¦éš›éŒ„éŸ³æ ¼å¼èª¿æ•´
        },
        body: bytes,
      );

      if (response.statusCode == 200) {
        final decoded = json.decode(response.body);
        final transcript = decoded['text'];


        /// ğŸ“ æ’å…¥ Logï¼šé¡¯ç¤º Whisper API çš„æ–‡å­—è½‰éŒ„å…§å®¹
        print('ğŸ“ Whisper è½‰éŒ„å…§å®¹ï¼š$transcript');

        // å„²å­˜ç‚º .txt æª”æ¡ˆ
        final dir = await getApplicationDocumentsDirectory();
        final file = File('${dir.path}/transcription.txt');
        await file.writeAsString(transcript);

        print('ğŸ“„ æˆåŠŸå„²å­˜è½‰è­¯æ–‡å­—åˆ°ï¼š${file.path}');
        return file;
      } else {
        print('âŒ èªéŸ³è¾¨è­˜å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: ${response.statusCode}');
        print('å›æ‡‰å…§å®¹: ${response.body}');
        return null;
      }
    } catch (e) {
      print('âŒ ç™¼ç”ŸéŒ¯èª¤: $e');
      return null;
    }
  }

  // å›å‚³ transcription.txt çš„å®Œæ•´è·¯å¾‘
  Future<String> getTranscriptFilePath() async {
    final dir = await getApplicationDocumentsDirectory();
    return '${dir.path}/transcription.txt';
  }

}

